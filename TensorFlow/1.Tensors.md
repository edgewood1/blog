### TensorFlow

**What is a tensor?**

- a data structure that represents a multi-dimensional array of elements.
- this array can be used to represent photos or sentences or other signals

**What are some Tensor attributes**

Rank - number of dimensions it has (a scalar has a rank of 0, a vector 1, a matrix 2, a tensor 3+. (3D tensors, or rows of 3D would be 4D).  Higher rank tensors are usted in image-processing, video analysis, etc. 

Shape - the size of each dimension - the number of elements within each axis. A shape of (3, 4) has 3 rows and 4 columns

Data type - elements in a tensor array can be of a certain data type: string, int64, etc

__What are some operations performed on a tensor__
math (add, multiply)
Element-wise operations
Matrix operations

__Other terms__

Computational Graphs - represents the operations and flow of data between tensors.  Tensors flow through the graph as operations are performed on them to product output tensors. 

TensorFlow session - the execution of computational graph that will obtain the result of our work. We must create the session `tf.Session() as ses` and run it `ses.run()`. 

__The basic structure of a TensorFlow program__

1. create tensors
2. Build computational graphs
3. Run session to execute the graph and obtain results.

```
import tensorflow as tf

# Create a computational graph
a = tf.constant(5)  # Create a constant tensor with value 5
b = tf.constant(3)  # Create a constant tensor with value 3
c = tf.add(a, b)    # Add the tensors a and b

# Run a TensorFlow session to execute the graph
with tf.Session() as sess:
    result = sess.run(c)
    print("The result of adding a and b is:", result)
```

__Level 2__

Tensors can be constants or mutable (able to be transformed).  

Placeholders - an empty tensor that will be fed with actual data later.  You could define is it as a float type thus: `tf.float32`.  

Variables - tensors whose values can be changed during execution of a computational graph.  This var must be initialized first.  To do initialize all the variables in a graph, use `tf.global_variables_initializer()` 

Below, we evaluate the comp. graph multiple times with different values for `a` 

We can evaluate the graph multiple time with different values for `a` by adding the `feed_dict` argument, wihc provides actual values for the placeholder: `a`

```
import tensorflow as tf

# Create a computational graph
a = tf.placeholder(tf.float32)  # Create a placeholder for a tensor of type float32
b = tf.Variable(3.0)  # Create a variable tensor with an initial value of 3.0
c = tf.add(a, b)  # Add the tensors a and b

# Initialize variables
init = tf.global_variables_initializer()

# Run a TensorFlow session to execute the graph

    with tf.Session() as sess:
    sess.run(init)  # Initialize the variables

    # Evaluate the computational graph with different values for a
    result1 = sess.run(c, feed_dict={a: 5.0})
    result2 = sess.run(c, feed_dict={a: 10.0})

    print("The result of adding a and b with a=5.0 is:", result1)
    print("The result of adding a and b with a=10.0 is:", result2)
```
Concept set three

`Variable Size Placeholder` - We modify the placeholder a by specifying `shape=[None]`, which allows the tensor to have a variable size. By setting the shape to [None], we indicate that the tensor can have any number of elements along the first dimension. This flexibility allows us to feed tensors of different lengths to the computational graph.

`Variable Initialization with an Array`: Instead of initializing the variable `b` with a single value, we now initialize it with an array of values: `[1.0, 2.0, 3.0]`. This creates a variable tensor with multiple elements.

`Element-wise Addition and Mean`: In addition to adding tensors `a` and `b` element-wise, we introduce the `tf.reduce_mean()` function to calculate the mean of the resulting tensor `c`. The `tf.reduce_mean()` operation reduces the tensor to a single scalar value by computing the mean of all its elements.

`Element-wise` is an operation performed independnetly on each element of one or more tensors, without any interaction between the element.  This results in a new tensor of the same shape. 

```
A = [1, 2, 3]
B = [4, 5, 6]
```
Element-wise addition between A and B would result in a new tensor C where each element is the sum of the corresponding elements of A and B:

`C = [1 + 4, 2 + 5, 3 + 6] = [5, 7, 9]`

`Running Multiple Operations`: We modify the `sess.run()` call to evaluate multiple tensors simultaneously. By passing a list of tensors `[c, mean_c], `we obtain the values of both c and mean_c in a single execution.

```import tensorflow as tf

# Create a computational graph
a = tf.placeholder(tf.float32, shape=[None])  # Create a placeholder for a tensor with variable size
b = tf.Variable([1.0, 2.0, 3.0])  # Create a variable tensor with an initial array value
c = tf.add(a, b)  # Add the tensors a and b element-wise
mean_c = tf.reduce_mean(c)  # Calculate the mean of tensor c

# Initialize variables
init = tf.global_variables_initializer()

# Run a TensorFlow session to execute the graph
with tf.Session() as sess:
    sess.run(init)  # Initialize the variables

    # Evaluate the computational graph with different values for a
    result1, mean1 = sess.run([c, mean_c], feed_dict={a: [2.0, 3.0, 4.0]})
    result2, mean2 = sess.run([c, mean_c], feed_dict={a: [5.0, 6.0, 7.0, 8.0, 9.0]})

# We print the results of c and mean_c for each evaluation to observe the element-wise addition and the mean of the resulting tensor.

    print("Result 1 (c):", result1)
    print("Mean of Result 1 (mean_c):", mean1)
    print("Result 2 (c):", result2)
    print("Mean of Result 2 (mean_c):", mean2)
```
